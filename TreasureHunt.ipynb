{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TreasureHunt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyME6PSLkQU8FdRiVbJ2002X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kailing231/treasurecube/blob/main/TreasureHunt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pam8MOrgsMVB"
      },
      "source": [
        "**CZ3005 Lab 2 Reinforcement Learning Code Implementation - Leong Kai Ling U1821434B**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf_rUCCYsID0"
      },
      "source": [
        "below code is from provided **environment.py** and is not modified"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiPfwcfVgNvV"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class AbstractEnvironment(ABC):\n",
        "    def __init__(self):\n",
        "        self.agent_sign = '+'\n",
        "        self.goal_sign = 'G'\n",
        "        self.corridor_sign = '-'\n",
        "\n",
        "    def render(self):\n",
        "        raise NotImplemented\n",
        "\n",
        "    def reset(self):\n",
        "        raise NotImplemented\n",
        "\n",
        "    def step(self, action):\n",
        "        raise NotImplemented\n",
        "\n",
        "class TreasureCube(AbstractEnvironment):\n",
        "    def __init__(self, max_step=20):\n",
        "        super(TreasureCube, self).__init__()\n",
        "        self.dim = 4\n",
        "        self.max_step = max_step\n",
        "        self.curr_pos = [0, 0, 0]  # (z, x, y)\n",
        "        self.time_step = 0\n",
        "        self.end_pos = [self.dim - 1, self.dim - 1, self.dim - 1]\n",
        "        self.visual_state = []\n",
        "        self.seed = None\n",
        "        self.set_seed()\n",
        "        self.all_actions = ['right', 'left', 'up', 'down', 'forward', 'backward']\n",
        "        self.slip_actions = dict()\n",
        "        self.set_action_rules()\n",
        "\n",
        "    def reset(self):\n",
        "        self.curr_pos = [0, 0, 0]\n",
        "        self.time_step = 0\n",
        "        self.end_pos = [self.dim - 1, self.dim - 1, self.dim - 1]\n",
        "        self._reset_visual_states(self.curr_pos, self.end_pos)\n",
        "        return ''.join(str(pos) for pos in self.curr_pos)\n",
        "\n",
        "    def step(self, action, stochastic=True):\n",
        "        in_action = action  # action from agent\n",
        "        assert action in self.all_actions\n",
        "        reward = -0.1\n",
        "        is_terminate = False\n",
        "        pre_pos = self.curr_pos\n",
        "        r = random.random()\n",
        "        if action == 'right':\n",
        "            if r < 0.1:\n",
        "                action = 'up'\n",
        "            elif r < 0.2:\n",
        "                action = 'down'\n",
        "            elif r < 0.3:\n",
        "                action = 'forward'\n",
        "            elif r < 0.4:\n",
        "                action = 'backward'\n",
        "            else:\n",
        "                action = 'right'\n",
        "        elif action == 'left':\n",
        "            if r < 0.1:\n",
        "                action = 'up'\n",
        "            elif r < 0.2:\n",
        "                action = 'down'\n",
        "            elif r < 0.3:\n",
        "                action = 'forward'\n",
        "            elif r < 0.4:\n",
        "                action = 'backward'\n",
        "            else:\n",
        "                action = 'left'\n",
        "        elif action == 'up':\n",
        "            if r < 0.1:\n",
        "                action = 'left'\n",
        "            elif r < 0.2:\n",
        "                action = 'right'\n",
        "            elif r < 0.3:\n",
        "                action = 'forward'\n",
        "            elif r < 0.4:\n",
        "                action = 'backward'\n",
        "            else:\n",
        "                action = 'up'\n",
        "        elif action == 'down':\n",
        "            if r < 0.1:\n",
        "                action = 'left'\n",
        "            elif r < 0.2:\n",
        "                action = 'right'\n",
        "            elif r < 0.3:\n",
        "                action = 'forward'\n",
        "            elif r < 0.4:\n",
        "                action = 'backward'\n",
        "            else:\n",
        "                action = 'down'\n",
        "        elif action == 'forward':\n",
        "            if r < 0.1:\n",
        "                action = 'left'\n",
        "            elif r < 0.2:\n",
        "                action = 'right'\n",
        "            elif r < 0.3:\n",
        "                action = 'up'\n",
        "            elif r < 0.4:\n",
        "                action = 'down'\n",
        "            else:\n",
        "                action = 'forward'\n",
        "        else:\n",
        "            if r < 0.1:\n",
        "                action = 'left'\n",
        "            elif r < 0.2:\n",
        "                action = 'right'\n",
        "            elif r < 0.3:\n",
        "                action = 'up'\n",
        "            elif r < 0.4:\n",
        "                action = 'down'\n",
        "            else:\n",
        "                action = 'backward'\n",
        "\n",
        "        if not stochastic:\n",
        "            action = in_action\n",
        "\n",
        "        assert action in self.all_actions\n",
        "        if action == 'left':\n",
        "            if self.curr_pos[1] == 0:  # wall\n",
        "                pass\n",
        "            else:\n",
        "                self.curr_pos[1] -= 1\n",
        "        elif action == 'right':\n",
        "            if self.curr_pos[1] == self.dim - 1:  # wall\n",
        "                pass\n",
        "            elif self.curr_pos[1] == self.dim - 2 and self.curr_pos[0] == self.dim - 1 and self.curr_pos[\n",
        "                2] == self.dim - 1:\n",
        "                self.curr_pos[1] += 1\n",
        "                is_terminate = True\n",
        "                reward = 1\n",
        "            else:\n",
        "                self.curr_pos[1] += 1\n",
        "\n",
        "        elif action == 'forward':\n",
        "            if self.curr_pos[0] == self.dim - 1:  # wall\n",
        "                pass\n",
        "            elif self.curr_pos[0] == self.dim - 2 and self.curr_pos[1] == self.dim - 1 and self.curr_pos[\n",
        "                2] == self.dim - 1:\n",
        "                self.curr_pos[0] += 1\n",
        "                is_terminate = True\n",
        "                reward = 1\n",
        "            else:\n",
        "                self.curr_pos[0] += 1\n",
        "        elif action == 'backward':\n",
        "            if self.curr_pos[0] == 0:  # wall\n",
        "                pass\n",
        "            else:\n",
        "                self.curr_pos[0] -= 1\n",
        "\n",
        "        elif action == 'up':\n",
        "            if self.curr_pos[2] == self.dim - 1:  # wall\n",
        "                pass\n",
        "            elif self.curr_pos[2] == self.dim - 2 and self.curr_pos[0] == self.dim - 1 and self.curr_pos[\n",
        "                1] == self.dim - 1:\n",
        "                self.curr_pos[2] += 1\n",
        "                is_terminate = True\n",
        "                reward = 1\n",
        "            else:\n",
        "                self.curr_pos[2] += 1\n",
        "        elif action == 'down':\n",
        "            if self.curr_pos[2] == 0:\n",
        "                pass\n",
        "            else:\n",
        "                self.curr_pos[2] -= 1\n",
        "\n",
        "        assert action in self.all_actions\n",
        "        self.time_step += 1\n",
        "        if self.time_step == self.max_step - 1:\n",
        "            is_terminate = True\n",
        "\n",
        "        self._reset_visual_states(self.curr_pos, self.end_pos)\n",
        "        return reward, is_terminate, ''.join(str(pos) for pos in self.curr_pos)\n",
        "\n",
        "    def render(self):\n",
        "        print(' '.join(['*'] * self.dim))\n",
        "        for i in range(self.dim):\n",
        "            for line in self.visual_state[i]:\n",
        "                print(' '.join(line))\n",
        "            print(' '.join(['#'] * self.dim))\n",
        "        print(' '.join(['*'] * self.dim))\n",
        "\n",
        "    def set_seed(self, seed=10086):\n",
        "        self.seed = seed\n",
        "        random.seed(seed)\n",
        "\n",
        "    def _reset_visual_states(self, agent_pos, goal_pos):\n",
        "        self.visual_state = [[[self.corridor_sign] * self.dim for _ in range(self.dim)] for _ in range(self.dim)]\n",
        "        self.visual_state[agent_pos[0]][agent_pos[1]][agent_pos[2]] = self.agent_sign\n",
        "        self.visual_state[goal_pos[0]][goal_pos[1]][goal_pos[2]] = self.goal_sign\n",
        "\n",
        "    def set_action_rules(self):\n",
        "        self.slip_actions['right'] = ['up', 'down', 'forward', 'backward', 'right']\n",
        "        self.slip_actions['left'] = ['up', 'down', 'forward', 'backward', 'left']\n",
        "        self.slip_actions['up'] = ['left', 'right', 'forward', 'backward', 'up']\n",
        "        self.slip_actions['down'] = ['left', 'right', 'forward', 'backward', 'down']\n",
        "        self.slip_actions['forward'] = ['left', 'right', 'up', 'down', 'forward']\n",
        "        self.slip_actions['backward'] = ['left', 'right', 'up', 'down', 'backward']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAUY_iV0h6r7"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "below code is from provided **test.py** and is split into different sections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtPeHBGVhAPt"
      },
      "source": [
        "import argparse\n",
        "import random\n",
        "\n",
        "import pandas as pd # added for DataFrame"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuqirUnIF2vM"
      },
      "source": [
        "class RandomAgent(object):\n",
        "    def __init__(self):\n",
        "        self.action_space = ['left','right','forward','backward','up','down'] # in TreasureCube\n",
        "        # initialise Q-table \n",
        "        length = 4 # coordinates range = [0,3]\n",
        "        indexnames = []\n",
        "        for x in range(length):\n",
        "            for y in range(length):\n",
        "                for z in range(length):\n",
        "                  indexnames.append(str(x) + str(y) + str(z))\n",
        "        # initialise all value = 0\n",
        "        self.Q = pd.DataFrame(0, index=indexnames, columns=self.action_space)\n",
        "        \n",
        "    def take_action(self, state):\n",
        "      epsilon = 0.01\n",
        "      if random.uniform(0, 1) < epsilon:\n",
        "          action = random.choice(self.action_space) # choose random action\n",
        "      else:\n",
        "          action = self.Q.loc[state].idxmax() # or choose highest action\n",
        "      return action\n",
        "\n",
        "    def train(self, state, action, next_state, reward):\n",
        "      alpha = 0.5 # learning rate\n",
        "      gamma = 0.99 # discount factor\n",
        "\n",
        "      old_value = self.Q.loc[state, action] # old Q(s,a)\n",
        "      next_max = self.Q.loc[next_state].max() # max of Q(s',a)\n",
        "      # store new Q(s,a) = old Q(s,a) + alpha * (reward + gamma*(max of Q(s',a)) - old Q(s,a))\n",
        "      new_value = old_value + alpha * (reward + (gamma * next_max) - old_value)\n",
        "      self.Q.loc[state, action] = new_value # new Q(s,a)\n",
        "\n",
        "    # test agent after q table is populated\n",
        "    def test_agent(self, max_step=100): # TODO\n",
        "      self.max_step = max_step"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9skVidmAt3r"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Below is the code from provided **test_cube()** in **test.py**\n",
        "<br> Create the environment and agent. Run the agent to populate the Q-table with multiple episodes and multiple steps.\n",
        "<br> In addition, added DataFrame to track episode reward per episode.\n",
        "<br> max_episode = 500 and max_step = 500, starts at 0 and ends at 499"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrA7v6e2DnTU",
        "outputId": "17074c12-7a21-46c4-bca0-b5b40c34b61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "max_episode = 500\n",
        "max_step = 500\n",
        "\n",
        "# added to keep track of episode reward per episode\n",
        "df_ep_reward = pd.DataFrame(0, index=range(0,max_episode), columns=[\"reward\"])\n",
        "\n",
        "env = TreasureCube(max_step=max_step)\n",
        "agent = RandomAgent()\n",
        "\n",
        "for epsisode_num in range(0, max_episode):\n",
        "    state = env.reset()\n",
        "    terminate = False\n",
        "    t = 0\n",
        "    episode_reward = 0\n",
        "\n",
        "    while not terminate:        \n",
        "        action = agent.take_action(state) # choose a random action or highest action\n",
        "\n",
        "        reward, terminate, next_state = env.step(action)\n",
        "        episode_reward += reward\n",
        "\n",
        "        # you can comment the following two lines, if the output is too much\n",
        "        # env.render() # comment\n",
        "        # print(f'step: {t}, action: {action}, reward: {reward}') # comment\n",
        "\n",
        "        t += 1\n",
        "        agent.train(state, action, next_state, reward) # implemented Q-Learning\n",
        "        state = next_state\n",
        "    print(f'epsisode: {epsisode_num}, total_steps: {t} episode reward: {episode_reward}')\n",
        "    # added to store episode reward per episode\n",
        "    df_ep_reward.loc[epsisode_num] = episode_reward"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epsisode: 0, total_steps: 54 episode reward: -4.299999999999997\n",
            "epsisode: 1, total_steps: 187 episode reward: -17.599999999999994\n",
            "epsisode: 2, total_steps: 69 episode reward: -5.799999999999992\n",
            "epsisode: 3, total_steps: 113 episode reward: -10.199999999999976\n",
            "epsisode: 4, total_steps: 92 episode reward: -8.099999999999984\n",
            "epsisode: 5, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 6, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 7, total_steps: 163 episode reward: -15.19999999999996\n",
            "epsisode: 8, total_steps: 233 episode reward: -22.20000000000006\n",
            "epsisode: 9, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 10, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 11, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 12, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 13, total_steps: 37 episode reward: -2.600000000000002\n",
            "epsisode: 14, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 15, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 16, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 17, total_steps: 50 episode reward: -3.8999999999999986\n",
            "epsisode: 18, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 19, total_steps: 51 episode reward: -3.9999999999999982\n",
            "epsisode: 20, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 21, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 22, total_steps: 57 episode reward: -4.599999999999996\n",
            "epsisode: 23, total_steps: 48 episode reward: -3.6999999999999993\n",
            "epsisode: 24, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 25, total_steps: 31 episode reward: -2.0000000000000013\n",
            "epsisode: 26, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 27, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 28, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 29, total_steps: 58 episode reward: -4.699999999999996\n",
            "epsisode: 30, total_steps: 33 episode reward: -2.2000000000000015\n",
            "epsisode: 31, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 32, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 33, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 34, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 35, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 36, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 37, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 38, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 39, total_steps: 50 episode reward: -3.8999999999999986\n",
            "epsisode: 40, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 41, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 42, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 43, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 44, total_steps: 46 episode reward: -3.5\n",
            "epsisode: 45, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 46, total_steps: 40 episode reward: -2.900000000000002\n",
            "epsisode: 47, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 48, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 49, total_steps: 35 episode reward: -2.4000000000000017\n",
            "epsisode: 50, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 51, total_steps: 41 episode reward: -3.0000000000000018\n",
            "epsisode: 52, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 53, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 54, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 55, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 56, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 57, total_steps: 40 episode reward: -2.900000000000002\n",
            "epsisode: 58, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 59, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 60, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 61, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 62, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 63, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 64, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 65, total_steps: 35 episode reward: -2.4000000000000017\n",
            "epsisode: 66, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 67, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 68, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 69, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 70, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 71, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 72, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 73, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 74, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 75, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 76, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 77, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 78, total_steps: 43 episode reward: -3.200000000000001\n",
            "epsisode: 79, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 80, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 81, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 82, total_steps: 45 episode reward: -3.4000000000000004\n",
            "epsisode: 83, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 84, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 85, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 86, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 87, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 88, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 89, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 90, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 91, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 92, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 93, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 94, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 95, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 96, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 97, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 98, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 99, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 100, total_steps: 29 episode reward: -1.8000000000000012\n",
            "epsisode: 101, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 102, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 103, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 104, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 105, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 106, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 107, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 108, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 109, total_steps: 34 episode reward: -2.3000000000000016\n",
            "epsisode: 110, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 111, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 112, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 113, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 114, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 115, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 116, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 117, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 118, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 119, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 120, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 121, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 122, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 123, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 124, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 125, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 126, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 127, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 128, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 129, total_steps: 39 episode reward: -2.800000000000002\n",
            "epsisode: 130, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 131, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 132, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 133, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 134, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 135, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 136, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 137, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 138, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 139, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 140, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 141, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 142, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 143, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 144, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 145, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 146, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 147, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 148, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 149, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 150, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 151, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 152, total_steps: 33 episode reward: -2.2000000000000015\n",
            "epsisode: 153, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 154, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 155, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 156, total_steps: 37 episode reward: -2.600000000000002\n",
            "epsisode: 157, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 158, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 159, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 160, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 161, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 162, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 163, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 164, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 165, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 166, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 167, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 168, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 169, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 170, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 171, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 172, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 173, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 174, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 175, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 176, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 177, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 178, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 179, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 180, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 181, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 182, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 183, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 184, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 185, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 186, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 187, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 188, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 189, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 190, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 191, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 192, total_steps: 40 episode reward: -2.900000000000002\n",
            "epsisode: 193, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 194, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 195, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 196, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 197, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 198, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 199, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 200, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 201, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 202, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 203, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 204, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 205, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 206, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 207, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 208, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 209, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 210, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 211, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 212, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 213, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 214, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 215, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 216, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 217, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 218, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 219, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 220, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 221, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 222, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 223, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 224, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 225, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 226, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 227, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 228, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 229, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 230, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 231, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 232, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 233, total_steps: 34 episode reward: -2.3000000000000016\n",
            "epsisode: 234, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 235, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 236, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 237, total_steps: 39 episode reward: -2.800000000000002\n",
            "epsisode: 238, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 239, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 240, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 241, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 242, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 243, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 244, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 245, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 246, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 247, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 248, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 249, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 250, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 251, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 252, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 253, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 254, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 255, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 256, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 257, total_steps: 40 episode reward: -2.900000000000002\n",
            "epsisode: 258, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 259, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 260, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 261, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 262, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 263, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 264, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 265, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 266, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 267, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 268, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 269, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 270, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 271, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 272, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 273, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 274, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 275, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 276, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 277, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 278, total_steps: 31 episode reward: -2.0000000000000013\n",
            "epsisode: 279, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 280, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 281, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 282, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 283, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 284, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 285, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 286, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 287, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 288, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 289, total_steps: 34 episode reward: -2.3000000000000016\n",
            "epsisode: 290, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 291, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 292, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 293, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 294, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 295, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 296, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 297, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 298, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 299, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 300, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 301, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 302, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 303, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 304, total_steps: 29 episode reward: -1.8000000000000012\n",
            "epsisode: 305, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 306, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 307, total_steps: 29 episode reward: -1.8000000000000012\n",
            "epsisode: 308, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 309, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 310, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 311, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 312, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 313, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 314, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 315, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 316, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 317, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 318, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 319, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 320, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 321, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 322, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 323, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 324, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 325, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 326, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 327, total_steps: 34 episode reward: -2.3000000000000016\n",
            "epsisode: 328, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 329, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 330, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 331, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 332, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 333, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 334, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 335, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 336, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 337, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 338, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 339, total_steps: 31 episode reward: -2.0000000000000013\n",
            "epsisode: 340, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 341, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 342, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 343, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 344, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 345, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 346, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 347, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 348, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 349, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 350, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 351, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 352, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 353, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 354, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 355, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 356, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 357, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 358, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 359, total_steps: 33 episode reward: -2.2000000000000015\n",
            "epsisode: 360, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 361, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 362, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 363, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 364, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 365, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 366, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 367, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 368, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 369, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 370, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 371, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 372, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 373, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 374, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 375, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 376, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 377, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 378, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 379, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 380, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 381, total_steps: 35 episode reward: -2.4000000000000017\n",
            "epsisode: 382, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 383, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 384, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 385, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 386, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 387, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 388, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 389, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 390, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 391, total_steps: 36 episode reward: -2.5000000000000018\n",
            "epsisode: 392, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 393, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 394, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 395, total_steps: 37 episode reward: -2.600000000000002\n",
            "epsisode: 396, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 397, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 398, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 399, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 400, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 401, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 402, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 403, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 404, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 405, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 406, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 407, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 408, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 409, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 410, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 411, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 412, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 413, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 414, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 415, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 416, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 417, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 418, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 419, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 420, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 421, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 422, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 423, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 424, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 425, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 426, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 427, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 428, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 429, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 430, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 431, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 432, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 433, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 434, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 435, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 436, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 437, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 438, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 439, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 440, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 441, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 442, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 443, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 444, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 445, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 446, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 447, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 448, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 449, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 450, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 451, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 452, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 453, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 454, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 455, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 456, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 457, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 458, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 459, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 460, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 461, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 462, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 463, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 464, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 465, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 466, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 467, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 468, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 469, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 470, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 471, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 472, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 473, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 474, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 475, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 476, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 477, total_steps: 31 episode reward: -2.0000000000000013\n",
            "epsisode: 478, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 479, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 480, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 481, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 482, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 483, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 484, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 485, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 486, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 487, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 488, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 489, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 490, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 491, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 492, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 493, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 494, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 495, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 496, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 497, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 498, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 499, total_steps: 14 episode reward: -0.30000000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TztDABoVFpz2"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "plot the learning progress: episode rewards vs. episodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyxJMT7fFusV",
        "outputId": "816f0ae7-ac6e-4355-df71-724460930e9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df_ep_reward"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reward</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-4.300000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.760000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-5.800000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.020000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-8.100000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>2.000000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>-7.000000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1.110223e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>-1.000000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>-3.000000e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           reward\n",
              "0   -4.300000e+00\n",
              "1   -1.760000e+01\n",
              "2   -5.800000e+00\n",
              "3   -1.020000e+01\n",
              "4   -8.100000e+00\n",
              "..            ...\n",
              "495  2.000000e-01\n",
              "496 -7.000000e-01\n",
              "497  1.110223e-16\n",
              "498 -1.000000e-01\n",
              "499 -3.000000e-01\n",
              "\n",
              "[500 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJaCvvyvG7JK"
      },
      "source": [
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPpVDcf0IkXG",
        "outputId": "040f8c82-435c-438b-add4-c3576636cfc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "plt.figure(figsize=(30,10))\n",
        "\n",
        "plt.plot(df_ep_reward, \"o\") # todo scatter plot\n",
        "# plt.plot(df_ep_reward) \n",
        "\n",
        "plt.xlabel('episode') # x-axis label\n",
        "plt.ylabel('episode reward') # y-axis label\n",
        "plt.title('episode reward per episode') # plot title\n",
        "plt.xticks(np.arange(0, 501, step=50)) # x-axis step = 50\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2160x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa3JV8qmAnIN"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "test populated Q-table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7QGjEzLIU44"
      },
      "source": [
        "max_episode = 100\n",
        "avg_steps = 0\n",
        "# test agent with populated q table\n",
        "for epsisode_num in range(0, max_episode):\n",
        "    state = env.reset()\n",
        "    terminate = False\n",
        "    t = 0\n",
        "    episode_reward = 0\n",
        "\n",
        "    while not terminate:        \n",
        "        action = agent.take_action(state) # choose a random action or highest action\n",
        "\n",
        "        reward, terminate, next_state = env.step(action)\n",
        "        episode_reward += reward\n",
        "        t += 1\n",
        "        # agent.train(state, action, next_state, reward)\n",
        "        state = next_state\n",
        "    print(f'epsisode: {epsisode_num}, total_steps: {t} episode reward: {episode_reward}')\n",
        "    # compute avg steps\n",
        "    avg_steps += t\n",
        "\n",
        "# end of loop\n",
        "print(\"Averge steps of agent per episode = \", avg_steps/max_episode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD7O_2uOGgh5"
      },
      "source": [
        "# agent.Q.to_csv(r'q_table_2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc-52JbiHc-U"
      },
      "source": [
        "agent.Q"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}