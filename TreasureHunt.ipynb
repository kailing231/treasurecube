{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TreasureHunt.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lf_rUCCYsID0"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOXEh10BZbCNRNqpbAK0BIU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kailing231/treasurecube/blob/main/TreasureHunt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pam8MOrgsMVB"
      },
      "source": [
        "**CZ3005 Lab 2 Reinforcement Learning Code Implementation**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf_rUCCYsID0"
      },
      "source": [
        "# `environment.py`\n",
        "Below code is from provided `environment.py` and is not modified"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiPfwcfVgNvV"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "class AbstractEnvironment(ABC):\n",
        "    def __init__(self):\n",
        "        self.agent_sign = '+'\n",
        "        self.goal_sign = 'G'\n",
        "        self.corridor_sign = '-'\n",
        "\n",
        "    def render(self):\n",
        "        raise NotImplemented\n",
        "\n",
        "    def reset(self):\n",
        "        raise NotImplemented\n",
        "\n",
        "    def step(self, action):\n",
        "        raise NotImplemented\n",
        "\n",
        "class TreasureCube(AbstractEnvironment):\n",
        "    def __init__(self, max_step=20):\n",
        "        super(TreasureCube, self).__init__()\n",
        "        self.dim = 4\n",
        "        self.max_step = max_step\n",
        "        self.curr_pos = [0, 0, 0]  # (z, x, y)\n",
        "        self.time_step = 0\n",
        "        self.end_pos = [self.dim - 1, self.dim - 1, self.dim - 1]\n",
        "        self.visual_state = []\n",
        "        self.seed = None\n",
        "        self.set_seed()\n",
        "        self.all_actions = ['right', 'left', 'up', 'down', 'forward', 'backward']\n",
        "        self.slip_actions = dict()\n",
        "        self.set_action_rules()\n",
        "\n",
        "    def reset(self):\n",
        "        self.curr_pos = [0, 0, 0]\n",
        "        self.time_step = 0\n",
        "        self.end_pos = [self.dim - 1, self.dim - 1, self.dim - 1]\n",
        "        self._reset_visual_states(self.curr_pos, self.end_pos)\n",
        "        return ''.join(str(pos) for pos in self.curr_pos)\n",
        "\n",
        "    def step(self, action, stochastic=True):\n",
        "        in_action = action  # action from agent\n",
        "        assert action in self.all_actions\n",
        "        reward = -0.1\n",
        "        is_terminate = False\n",
        "        pre_pos = self.curr_pos\n",
        "        r = random.random()\n",
        "        if action == 'right':\n",
        "            if r < 0.1:\n",
        "                action = 'up'\n",
        "            elif r < 0.2:\n",
        "                action = 'down'\n",
        "            elif r < 0.3:\n",
        "                action = 'forward'\n",
        "            elif r < 0.4:\n",
        "                action = 'backward'\n",
        "            else:\n",
        "                action = 'right'\n",
        "        elif action == 'left':\n",
        "            if r < 0.1:\n",
        "                action = 'up'\n",
        "            elif r < 0.2:\n",
        "                action = 'down'\n",
        "            elif r < 0.3:\n",
        "                action = 'forward'\n",
        "            elif r < 0.4:\n",
        "                action = 'backward'\n",
        "            else:\n",
        "                action = 'left'\n",
        "        elif action == 'up':\n",
        "            if r < 0.1:\n",
        "                action = 'left'\n",
        "            elif r < 0.2:\n",
        "                action = 'right'\n",
        "            elif r < 0.3:\n",
        "                action = 'forward'\n",
        "            elif r < 0.4:\n",
        "                action = 'backward'\n",
        "            else:\n",
        "                action = 'up'\n",
        "        elif action == 'down':\n",
        "            if r < 0.1:\n",
        "                action = 'left'\n",
        "            elif r < 0.2:\n",
        "                action = 'right'\n",
        "            elif r < 0.3:\n",
        "                action = 'forward'\n",
        "            elif r < 0.4:\n",
        "                action = 'backward'\n",
        "            else:\n",
        "                action = 'down'\n",
        "        elif action == 'forward':\n",
        "            if r < 0.1:\n",
        "                action = 'left'\n",
        "            elif r < 0.2:\n",
        "                action = 'right'\n",
        "            elif r < 0.3:\n",
        "                action = 'up'\n",
        "            elif r < 0.4:\n",
        "                action = 'down'\n",
        "            else:\n",
        "                action = 'forward'\n",
        "        else:\n",
        "            if r < 0.1:\n",
        "                action = 'left'\n",
        "            elif r < 0.2:\n",
        "                action = 'right'\n",
        "            elif r < 0.3:\n",
        "                action = 'up'\n",
        "            elif r < 0.4:\n",
        "                action = 'down'\n",
        "            else:\n",
        "                action = 'backward'\n",
        "\n",
        "        if not stochastic:\n",
        "            action = in_action\n",
        "\n",
        "        assert action in self.all_actions\n",
        "        if action == 'left':\n",
        "            if self.curr_pos[1] == 0:  # wall\n",
        "                pass\n",
        "            else:\n",
        "                self.curr_pos[1] -= 1\n",
        "        elif action == 'right':\n",
        "            if self.curr_pos[1] == self.dim - 1:  # wall\n",
        "                pass\n",
        "            elif self.curr_pos[1] == self.dim - 2 and self.curr_pos[0] == self.dim - 1 and self.curr_pos[\n",
        "                2] == self.dim - 1:\n",
        "                self.curr_pos[1] += 1\n",
        "                is_terminate = True\n",
        "                reward = 1\n",
        "            else:\n",
        "                self.curr_pos[1] += 1\n",
        "\n",
        "        elif action == 'forward':\n",
        "            if self.curr_pos[0] == self.dim - 1:  # wall\n",
        "                pass\n",
        "            elif self.curr_pos[0] == self.dim - 2 and self.curr_pos[1] == self.dim - 1 and self.curr_pos[\n",
        "                2] == self.dim - 1:\n",
        "                self.curr_pos[0] += 1\n",
        "                is_terminate = True\n",
        "                reward = 1\n",
        "            else:\n",
        "                self.curr_pos[0] += 1\n",
        "        elif action == 'backward':\n",
        "            if self.curr_pos[0] == 0:  # wall\n",
        "                pass\n",
        "            else:\n",
        "                self.curr_pos[0] -= 1\n",
        "\n",
        "        elif action == 'up':\n",
        "            if self.curr_pos[2] == self.dim - 1:  # wall\n",
        "                pass\n",
        "            elif self.curr_pos[2] == self.dim - 2 and self.curr_pos[0] == self.dim - 1 and self.curr_pos[\n",
        "                1] == self.dim - 1:\n",
        "                self.curr_pos[2] += 1\n",
        "                is_terminate = True\n",
        "                reward = 1\n",
        "            else:\n",
        "                self.curr_pos[2] += 1\n",
        "        elif action == 'down':\n",
        "            if self.curr_pos[2] == 0:\n",
        "                pass\n",
        "            else:\n",
        "                self.curr_pos[2] -= 1\n",
        "\n",
        "        assert action in self.all_actions\n",
        "        self.time_step += 1\n",
        "        if self.time_step == self.max_step - 1:\n",
        "            is_terminate = True\n",
        "\n",
        "        self._reset_visual_states(self.curr_pos, self.end_pos)\n",
        "        return reward, is_terminate, ''.join(str(pos) for pos in self.curr_pos)\n",
        "\n",
        "    def render(self):\n",
        "        print(' '.join(['*'] * self.dim))\n",
        "        for i in range(self.dim):\n",
        "            for line in self.visual_state[i]:\n",
        "                print(' '.join(line))\n",
        "            print(' '.join(['#'] * self.dim))\n",
        "        print(' '.join(['*'] * self.dim))\n",
        "\n",
        "    def set_seed(self, seed=10086):\n",
        "        self.seed = seed\n",
        "        random.seed(seed)\n",
        "\n",
        "    def _reset_visual_states(self, agent_pos, goal_pos):\n",
        "        self.visual_state = [[[self.corridor_sign] * self.dim for _ in range(self.dim)] for _ in range(self.dim)]\n",
        "        self.visual_state[agent_pos[0]][agent_pos[1]][agent_pos[2]] = self.agent_sign\n",
        "        self.visual_state[goal_pos[0]][goal_pos[1]][goal_pos[2]] = self.goal_sign\n",
        "\n",
        "    def set_action_rules(self):\n",
        "        self.slip_actions['right'] = ['up', 'down', 'forward', 'backward', 'right']\n",
        "        self.slip_actions['left'] = ['up', 'down', 'forward', 'backward', 'left']\n",
        "        self.slip_actions['up'] = ['left', 'right', 'forward', 'backward', 'up']\n",
        "        self.slip_actions['down'] = ['left', 'right', 'forward', 'backward', 'down']\n",
        "        self.slip_actions['forward'] = ['left', 'right', 'up', 'down', 'forward']\n",
        "        self.slip_actions['backward'] = ['left', 'right', 'up', 'down', 'backward']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAUY_iV0h6r7"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "# modified `test.py`\n",
        "Below code is from provided `test.py` and is split into different sections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtPeHBGVhAPt"
      },
      "source": [
        "import argparse\n",
        "import random\n",
        "\n",
        "import pandas as pd # added for DataFrame"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JeFR8UV-b6p"
      },
      "source": [
        "## `RandomAgent` class\n",
        "\n",
        "Modified to implement Q-Learning\n",
        "<br> Modified `take_action()` and `train()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuqirUnIF2vM"
      },
      "source": [
        "class RandomAgent(object):\n",
        "    def __init__(self):\n",
        "        self.action_space = ['left','right','forward','backward','up','down'] # in TreasureCube\n",
        "        # initialise Q-table \n",
        "        length = 4 # coordinates range = [0,3]\n",
        "        indexnames = []\n",
        "        for x in range(length):\n",
        "            for y in range(length):\n",
        "                for z in range(length):\n",
        "                  indexnames.append(str(x) + str(y) + str(z))\n",
        "        # initialise all value = 0\n",
        "        self.Q = pd.DataFrame(0, index=indexnames, columns=self.action_space)\n",
        "        \n",
        "    def take_action(self, state):\n",
        "      epsilon = 0.01\n",
        "      if random.uniform(0, 1) < epsilon:\n",
        "          action = random.choice(self.action_space) # choose random action\n",
        "      else:\n",
        "          action = self.Q.loc[state].idxmax() # or choose highest action\n",
        "      return action\n",
        "\n",
        "    def train(self, state, action, next_state, reward):\n",
        "      alpha = 0.5 # learning rate\n",
        "      gamma = 0.99 # discount factor\n",
        "\n",
        "      old_value = self.Q.loc[state, action] # old Q(s,a)\n",
        "      next_max = self.Q.loc[next_state].max() # max of Q(s',a)\n",
        "      # store new Q(s,a) = old Q(s,a) + alpha * (reward + gamma*(max of Q(s',a)) - old Q(s,a))\n",
        "      new_value = old_value + alpha * (reward + (gamma * next_max) - old_value)\n",
        "      self.Q.loc[state, action] = new_value # new Q(s,a)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9skVidmAt3r"
      },
      "source": [
        "## code from `test_cube()` in `test.py`\n",
        "Create the environment and agent. Run the agent to populate the Q-table with multiple episodes and multiple steps.\n",
        "<br> In addition, added DataFrame `df_ep_reward` to track episode reward per episode.\n",
        "<br> `max_episode = 500` and `max_step = 500`, starts at 0 and ends at 499\n",
        "<br> Lastly, added `steps_sum` to calculate average steps per episode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrA7v6e2DnTU",
        "outputId": "8ee62a09-ff2e-4efe-f5e9-0f7135c4b6a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "max_episode = 500\n",
        "max_step = 500\n",
        "steps_sum = 0\n",
        "\n",
        "# added to keep track of episode reward per episode\n",
        "df_ep_reward = pd.DataFrame(0, index=range(0,max_episode), columns=[\"reward\"])\n",
        "\n",
        "# code from test_cube() of test.py\n",
        "\n",
        "env = TreasureCube(max_step=max_step)\n",
        "agent = RandomAgent()\n",
        "\n",
        "for epsisode_num in range(0, max_episode):\n",
        "    state = env.reset()\n",
        "    terminate = False\n",
        "    t = 0\n",
        "    episode_reward = 0\n",
        "\n",
        "    while not terminate:        \n",
        "        action = agent.take_action(state) # choose a random action or highest action\n",
        "\n",
        "        reward, terminate, next_state = env.step(action)\n",
        "        episode_reward += reward\n",
        "\n",
        "        # you can comment the following two lines, if the output is too much\n",
        "        # env.render() # comment\n",
        "        # print(f'step: {t}, action: {action}, reward: {reward}') # comment\n",
        "\n",
        "        t += 1\n",
        "        agent.train(state, action, next_state, reward) # implemented Q-Learning\n",
        "        state = next_state\n",
        "    print(f'epsisode: {epsisode_num}, total_steps: {t} episode reward: {episode_reward}')\n",
        "    # added to store episode reward per episode\n",
        "    df_ep_reward.loc[epsisode_num] = episode_reward\n",
        "    steps_sum += t # added to store sum of steps\n",
        "\n",
        "print(\"Averge steps of agent per episode = \", steps_sum/epsisode_num)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epsisode: 0, total_steps: 54 episode reward: -4.299999999999997\n",
            "epsisode: 1, total_steps: 187 episode reward: -17.599999999999994\n",
            "epsisode: 2, total_steps: 69 episode reward: -5.799999999999992\n",
            "epsisode: 3, total_steps: 113 episode reward: -10.199999999999976\n",
            "epsisode: 4, total_steps: 92 episode reward: -8.099999999999984\n",
            "epsisode: 5, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 6, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 7, total_steps: 163 episode reward: -15.19999999999996\n",
            "epsisode: 8, total_steps: 233 episode reward: -22.20000000000006\n",
            "epsisode: 9, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 10, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 11, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 12, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 13, total_steps: 37 episode reward: -2.600000000000002\n",
            "epsisode: 14, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 15, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 16, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 17, total_steps: 50 episode reward: -3.8999999999999986\n",
            "epsisode: 18, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 19, total_steps: 51 episode reward: -3.9999999999999982\n",
            "epsisode: 20, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 21, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 22, total_steps: 57 episode reward: -4.599999999999996\n",
            "epsisode: 23, total_steps: 48 episode reward: -3.6999999999999993\n",
            "epsisode: 24, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 25, total_steps: 31 episode reward: -2.0000000000000013\n",
            "epsisode: 26, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 27, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 28, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 29, total_steps: 58 episode reward: -4.699999999999996\n",
            "epsisode: 30, total_steps: 33 episode reward: -2.2000000000000015\n",
            "epsisode: 31, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 32, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 33, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 34, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 35, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 36, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 37, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 38, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 39, total_steps: 50 episode reward: -3.8999999999999986\n",
            "epsisode: 40, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 41, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 42, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 43, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 44, total_steps: 46 episode reward: -3.5\n",
            "epsisode: 45, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 46, total_steps: 40 episode reward: -2.900000000000002\n",
            "epsisode: 47, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 48, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 49, total_steps: 35 episode reward: -2.4000000000000017\n",
            "epsisode: 50, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 51, total_steps: 41 episode reward: -3.0000000000000018\n",
            "epsisode: 52, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 53, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 54, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 55, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 56, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 57, total_steps: 40 episode reward: -2.900000000000002\n",
            "epsisode: 58, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 59, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 60, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 61, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 62, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 63, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 64, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 65, total_steps: 35 episode reward: -2.4000000000000017\n",
            "epsisode: 66, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 67, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 68, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 69, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 70, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 71, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 72, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 73, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 74, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 75, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 76, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 77, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 78, total_steps: 43 episode reward: -3.200000000000001\n",
            "epsisode: 79, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 80, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 81, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 82, total_steps: 45 episode reward: -3.4000000000000004\n",
            "epsisode: 83, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 84, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 85, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 86, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 87, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 88, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 89, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 90, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 91, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 92, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 93, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 94, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 95, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 96, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 97, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 98, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 99, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 100, total_steps: 29 episode reward: -1.8000000000000012\n",
            "epsisode: 101, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 102, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 103, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 104, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 105, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 106, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 107, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 108, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 109, total_steps: 34 episode reward: -2.3000000000000016\n",
            "epsisode: 110, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 111, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 112, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 113, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 114, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 115, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 116, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 117, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 118, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 119, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 120, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 121, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 122, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 123, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 124, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 125, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 126, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 127, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 128, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 129, total_steps: 39 episode reward: -2.800000000000002\n",
            "epsisode: 130, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 131, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 132, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 133, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 134, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 135, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 136, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 137, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 138, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 139, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 140, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 141, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 142, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 143, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 144, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 145, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 146, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 147, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 148, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 149, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 150, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 151, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 152, total_steps: 33 episode reward: -2.2000000000000015\n",
            "epsisode: 153, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 154, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 155, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 156, total_steps: 37 episode reward: -2.600000000000002\n",
            "epsisode: 157, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 158, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 159, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 160, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 161, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 162, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 163, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 164, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 165, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 166, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 167, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 168, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 169, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 170, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 171, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 172, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 173, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 174, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 175, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 176, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 177, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 178, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 179, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 180, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 181, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 182, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 183, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 184, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 185, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 186, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 187, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 188, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 189, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 190, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 191, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 192, total_steps: 40 episode reward: -2.900000000000002\n",
            "epsisode: 193, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 194, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 195, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 196, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 197, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 198, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 199, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 200, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 201, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 202, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 203, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 204, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 205, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 206, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 207, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 208, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 209, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 210, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 211, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 212, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 213, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 214, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 215, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 216, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 217, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 218, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 219, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 220, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 221, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 222, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 223, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 224, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 225, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 226, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 227, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 228, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 229, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 230, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 231, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 232, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 233, total_steps: 34 episode reward: -2.3000000000000016\n",
            "epsisode: 234, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 235, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 236, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 237, total_steps: 39 episode reward: -2.800000000000002\n",
            "epsisode: 238, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 239, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 240, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 241, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 242, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 243, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 244, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 245, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 246, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 247, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 248, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 249, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 250, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 251, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 252, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 253, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 254, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 255, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 256, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 257, total_steps: 40 episode reward: -2.900000000000002\n",
            "epsisode: 258, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 259, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 260, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 261, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 262, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 263, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 264, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 265, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 266, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 267, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 268, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 269, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 270, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 271, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 272, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 273, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 274, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 275, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 276, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 277, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 278, total_steps: 31 episode reward: -2.0000000000000013\n",
            "epsisode: 279, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 280, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 281, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 282, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 283, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 284, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 285, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 286, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 287, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 288, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 289, total_steps: 34 episode reward: -2.3000000000000016\n",
            "epsisode: 290, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 291, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 292, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 293, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 294, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 295, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 296, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 297, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 298, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 299, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 300, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 301, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 302, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 303, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 304, total_steps: 29 episode reward: -1.8000000000000012\n",
            "epsisode: 305, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 306, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 307, total_steps: 29 episode reward: -1.8000000000000012\n",
            "epsisode: 308, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 309, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 310, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 311, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 312, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 313, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 314, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 315, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 316, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 317, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 318, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 319, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 320, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 321, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 322, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 323, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 324, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 325, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 326, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 327, total_steps: 34 episode reward: -2.3000000000000016\n",
            "epsisode: 328, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 329, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 330, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 331, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 332, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 333, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 334, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 335, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 336, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 337, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 338, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 339, total_steps: 31 episode reward: -2.0000000000000013\n",
            "epsisode: 340, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 341, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 342, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 343, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 344, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 345, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 346, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 347, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 348, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 349, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 350, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 351, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 352, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 353, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 354, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 355, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 356, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 357, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 358, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 359, total_steps: 33 episode reward: -2.2000000000000015\n",
            "epsisode: 360, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 361, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 362, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 363, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 364, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 365, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 366, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 367, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 368, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 369, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 370, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 371, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 372, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 373, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 374, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 375, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 376, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 377, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 378, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 379, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 380, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 381, total_steps: 35 episode reward: -2.4000000000000017\n",
            "epsisode: 382, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 383, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 384, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 385, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 386, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 387, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 388, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 389, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 390, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 391, total_steps: 36 episode reward: -2.5000000000000018\n",
            "epsisode: 392, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 393, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 394, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 395, total_steps: 37 episode reward: -2.600000000000002\n",
            "epsisode: 396, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 397, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 398, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 399, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 400, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 401, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 402, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 403, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 404, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 405, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 406, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 407, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 408, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 409, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 410, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 411, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 412, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 413, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 414, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 415, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 416, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 417, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 418, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 419, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 420, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 421, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 422, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 423, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 424, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 425, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 426, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 427, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 428, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 429, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 430, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 431, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 432, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 433, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 434, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 435, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 436, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 437, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 438, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 439, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 440, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 441, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 442, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 443, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 444, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 445, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 446, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 447, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 448, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 449, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 450, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 451, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 452, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 453, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 454, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 455, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 456, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 457, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 458, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 459, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 460, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 461, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 462, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 463, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 464, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 465, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 466, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 467, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 468, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 469, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 470, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 471, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 472, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 473, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 474, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 475, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 476, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 477, total_steps: 31 episode reward: -2.0000000000000013\n",
            "epsisode: 478, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 479, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 480, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 481, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 482, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 483, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 484, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 485, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 486, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 487, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 488, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 489, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 490, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 491, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 492, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 493, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 494, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 495, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 496, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 497, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 498, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 499, total_steps: 14 episode reward: -0.30000000000000004\n",
            "Averge steps of agent per episode =  19.95390781563126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TztDABoVFpz2"
      },
      "source": [
        "## Plot the learning progress: episode rewards vs. episodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJaCvvyvG7JK"
      },
      "source": [
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPpVDcf0IkXG",
        "outputId": "795f5c6f-5b92-4770-d16f-db8f6783d5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "plt.figure(figsize=(20,8)) # resize plot\n",
        "plt.plot(df_ep_reward, \"o\")\n",
        "\n",
        "plt.xlabel('episode') # x-axis label\n",
        "plt.ylabel('episode reward') # y-axis label\n",
        "plt.title('episode reward per episode') # plot title\n",
        "plt.xticks(np.arange(0, 501, step=50)) # x-axis step = 50\n",
        "\n",
        "plt.savefig('plot_ep_reward.png', bbox_inches = 'tight', pad_inches = 0.1) # save plot as png file\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuKWDb2dqjAF",
        "outputId": "499a4cd5-1480-4c22-b878-daec52f2803c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Averge episode reward from test_cube() = \", df_ep_reward['reward'].mean())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Averge episode reward from test_cube() =  -0.8913999999999997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZqAu4GzSk87"
      },
      "source": [
        "## Show trained Q-table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc-52JbiHc-U",
        "outputId": "1f3f3ec2-c37b-42ac-bb97-9e5628711b24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "agent.Q.to_csv(r'q_table.csv') # save Q-table as csv file\n",
        "\n",
        "pd.set_option('display.max_rows', 100) # show Q-table here\n",
        "agent.Q"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>left</th>\n",
              "      <th>right</th>\n",
              "      <th>forward</th>\n",
              "      <th>backward</th>\n",
              "      <th>up</th>\n",
              "      <th>down</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000</th>\n",
              "      <td>-0.727493</td>\n",
              "      <td>-0.709291</td>\n",
              "      <td>-0.439680</td>\n",
              "      <td>-0.624663</td>\n",
              "      <td>-0.621734</td>\n",
              "      <td>-0.685483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>001</th>\n",
              "      <td>-0.575510</td>\n",
              "      <td>-0.299116</td>\n",
              "      <td>-0.580253</td>\n",
              "      <td>-0.564337</td>\n",
              "      <td>-0.571451</td>\n",
              "      <td>-0.584132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>002</th>\n",
              "      <td>-0.409343</td>\n",
              "      <td>-0.383465</td>\n",
              "      <td>-0.383260</td>\n",
              "      <td>-0.406132</td>\n",
              "      <td>-0.282102</td>\n",
              "      <td>-0.451487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003</th>\n",
              "      <td>-0.330279</td>\n",
              "      <td>-0.288272</td>\n",
              "      <td>-0.200506</td>\n",
              "      <td>-0.296275</td>\n",
              "      <td>-0.332725</td>\n",
              "      <td>-0.318419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>010</th>\n",
              "      <td>-0.648876</td>\n",
              "      <td>-0.625435</td>\n",
              "      <td>-0.246483</td>\n",
              "      <td>-0.601730</td>\n",
              "      <td>-0.478675</td>\n",
              "      <td>-0.639680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>011</th>\n",
              "      <td>-0.494845</td>\n",
              "      <td>-0.137551</td>\n",
              "      <td>-0.503505</td>\n",
              "      <td>-0.500063</td>\n",
              "      <td>-0.489243</td>\n",
              "      <td>-0.527051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>012</th>\n",
              "      <td>-0.372559</td>\n",
              "      <td>-0.358729</td>\n",
              "      <td>-0.394802</td>\n",
              "      <td>-0.391114</td>\n",
              "      <td>-0.181549</td>\n",
              "      <td>-0.405842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>013</th>\n",
              "      <td>-0.262582</td>\n",
              "      <td>0.201183</td>\n",
              "      <td>-0.273221</td>\n",
              "      <td>-0.247512</td>\n",
              "      <td>-0.210634</td>\n",
              "      <td>-0.256714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>020</th>\n",
              "      <td>-0.503763</td>\n",
              "      <td>-0.533528</td>\n",
              "      <td>-0.536116</td>\n",
              "      <td>-0.518705</td>\n",
              "      <td>-0.184594</td>\n",
              "      <td>-0.511744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>021</th>\n",
              "      <td>-0.476565</td>\n",
              "      <td>-0.406985</td>\n",
              "      <td>-0.429889</td>\n",
              "      <td>-0.446039</td>\n",
              "      <td>0.086096</td>\n",
              "      <td>-0.428947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>022</th>\n",
              "      <td>-0.287193</td>\n",
              "      <td>-0.294008</td>\n",
              "      <td>-0.257529</td>\n",
              "      <td>-0.271894</td>\n",
              "      <td>0.302627</td>\n",
              "      <td>-0.267942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>023</th>\n",
              "      <td>-0.207449</td>\n",
              "      <td>-0.230781</td>\n",
              "      <td>0.375436</td>\n",
              "      <td>-0.015739</td>\n",
              "      <td>-0.198596</td>\n",
              "      <td>-0.192132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>030</th>\n",
              "      <td>-0.447153</td>\n",
              "      <td>-0.488899</td>\n",
              "      <td>-0.510326</td>\n",
              "      <td>-0.488899</td>\n",
              "      <td>-0.365281</td>\n",
              "      <td>-0.455075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>031</th>\n",
              "      <td>-0.364457</td>\n",
              "      <td>-0.416799</td>\n",
              "      <td>-0.027034</td>\n",
              "      <td>-0.369950</td>\n",
              "      <td>-0.376162</td>\n",
              "      <td>-0.384085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>032</th>\n",
              "      <td>-0.282318</td>\n",
              "      <td>-0.183548</td>\n",
              "      <td>0.309098</td>\n",
              "      <td>-0.289379</td>\n",
              "      <td>-0.265154</td>\n",
              "      <td>-0.265890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>033</th>\n",
              "      <td>-0.241479</td>\n",
              "      <td>-0.272016</td>\n",
              "      <td>0.512946</td>\n",
              "      <td>-0.077382</td>\n",
              "      <td>-0.049500</td>\n",
              "      <td>-0.268600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>-0.565791</td>\n",
              "      <td>-0.557605</td>\n",
              "      <td>-0.306946</td>\n",
              "      <td>-0.593690</td>\n",
              "      <td>-0.545794</td>\n",
              "      <td>-0.545941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>-0.440782</td>\n",
              "      <td>-0.510128</td>\n",
              "      <td>-0.138927</td>\n",
              "      <td>-0.431649</td>\n",
              "      <td>-0.414145</td>\n",
              "      <td>-0.431542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>-0.351109</td>\n",
              "      <td>-0.350461</td>\n",
              "      <td>-0.350197</td>\n",
              "      <td>-0.356410</td>\n",
              "      <td>-0.112315</td>\n",
              "      <td>-0.379123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>-0.234954</td>\n",
              "      <td>0.116300</td>\n",
              "      <td>-0.229042</td>\n",
              "      <td>-0.252070</td>\n",
              "      <td>-0.263959</td>\n",
              "      <td>-0.215421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>-0.518060</td>\n",
              "      <td>-0.082275</td>\n",
              "      <td>-0.498799</td>\n",
              "      <td>-0.555309</td>\n",
              "      <td>-0.532275</td>\n",
              "      <td>-0.520876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>-0.369768</td>\n",
              "      <td>-0.076763</td>\n",
              "      <td>-0.412677</td>\n",
              "      <td>-0.407914</td>\n",
              "      <td>-0.326146</td>\n",
              "      <td>-0.406423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>-0.251992</td>\n",
              "      <td>-0.285361</td>\n",
              "      <td>-0.231699</td>\n",
              "      <td>-0.239732</td>\n",
              "      <td>0.026181</td>\n",
              "      <td>-0.244870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>-0.155895</td>\n",
              "      <td>0.176083</td>\n",
              "      <td>-0.173754</td>\n",
              "      <td>-0.167814</td>\n",
              "      <td>-0.174927</td>\n",
              "      <td>-0.160509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>-0.392719</td>\n",
              "      <td>-0.426442</td>\n",
              "      <td>0.033982</td>\n",
              "      <td>-0.330107</td>\n",
              "      <td>-0.428672</td>\n",
              "      <td>-0.420871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>-0.242263</td>\n",
              "      <td>-0.237164</td>\n",
              "      <td>-0.159277</td>\n",
              "      <td>-0.271578</td>\n",
              "      <td>0.261864</td>\n",
              "      <td>-0.240283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>-0.123061</td>\n",
              "      <td>-0.149314</td>\n",
              "      <td>-0.168367</td>\n",
              "      <td>-0.190554</td>\n",
              "      <td>0.107535</td>\n",
              "      <td>-0.207416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>-0.123778</td>\n",
              "      <td>0.361044</td>\n",
              "      <td>0.166270</td>\n",
              "      <td>-0.042239</td>\n",
              "      <td>-0.075000</td>\n",
              "      <td>-0.129641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>-0.317175</td>\n",
              "      <td>-0.343736</td>\n",
              "      <td>0.063371</td>\n",
              "      <td>-0.362607</td>\n",
              "      <td>-0.369596</td>\n",
              "      <td>-0.341701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>-0.198727</td>\n",
              "      <td>-0.186192</td>\n",
              "      <td>-0.192317</td>\n",
              "      <td>-0.186067</td>\n",
              "      <td>0.256258</td>\n",
              "      <td>-0.192226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>-0.161689</td>\n",
              "      <td>-0.149251</td>\n",
              "      <td>0.197351</td>\n",
              "      <td>-0.209039</td>\n",
              "      <td>-0.173816</td>\n",
              "      <td>-0.136751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>-0.112001</td>\n",
              "      <td>-0.112001</td>\n",
              "      <td>0.607120</td>\n",
              "      <td>-0.074750</td>\n",
              "      <td>-0.050000</td>\n",
              "      <td>0.164343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>-0.466588</td>\n",
              "      <td>-0.498225</td>\n",
              "      <td>-0.141782</td>\n",
              "      <td>-0.492023</td>\n",
              "      <td>-0.474595</td>\n",
              "      <td>-0.483339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>-0.332664</td>\n",
              "      <td>0.015541</td>\n",
              "      <td>-0.321412</td>\n",
              "      <td>-0.385102</td>\n",
              "      <td>-0.275829</td>\n",
              "      <td>-0.364409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>-0.198505</td>\n",
              "      <td>-0.219738</td>\n",
              "      <td>-0.017289</td>\n",
              "      <td>-0.198505</td>\n",
              "      <td>-0.215397</td>\n",
              "      <td>-0.223009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>-0.149251</td>\n",
              "      <td>0.350384</td>\n",
              "      <td>-0.167629</td>\n",
              "      <td>-0.136876</td>\n",
              "      <td>-0.161564</td>\n",
              "      <td>-0.198631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>-0.322608</td>\n",
              "      <td>0.071911</td>\n",
              "      <td>-0.331681</td>\n",
              "      <td>-0.332009</td>\n",
              "      <td>-0.370910</td>\n",
              "      <td>-0.312695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>-0.238677</td>\n",
              "      <td>0.086940</td>\n",
              "      <td>-0.276616</td>\n",
              "      <td>-0.214134</td>\n",
              "      <td>-0.214015</td>\n",
              "      <td>-0.295121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>-0.183067</td>\n",
              "      <td>0.419054</td>\n",
              "      <td>-0.135585</td>\n",
              "      <td>-0.149251</td>\n",
              "      <td>-0.136751</td>\n",
              "      <td>-0.175235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>-0.137000</td>\n",
              "      <td>0.557325</td>\n",
              "      <td>-0.102897</td>\n",
              "      <td>-0.112250</td>\n",
              "      <td>-0.124376</td>\n",
              "      <td>-0.099750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>-0.283623</td>\n",
              "      <td>0.212633</td>\n",
              "      <td>-0.125146</td>\n",
              "      <td>-0.195984</td>\n",
              "      <td>-0.281145</td>\n",
              "      <td>-0.277805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>-0.227449</td>\n",
              "      <td>-0.181176</td>\n",
              "      <td>0.256348</td>\n",
              "      <td>-0.134322</td>\n",
              "      <td>-0.195257</td>\n",
              "      <td>-0.182943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>-0.130203</td>\n",
              "      <td>-0.087933</td>\n",
              "      <td>-0.099750</td>\n",
              "      <td>-0.099750</td>\n",
              "      <td>0.555568</td>\n",
              "      <td>-0.105316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>-0.112001</td>\n",
              "      <td>0.637082</td>\n",
              "      <td>-0.074750</td>\n",
              "      <td>-0.074750</td>\n",
              "      <td>0.180955</td>\n",
              "      <td>-0.074750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>-0.186742</td>\n",
              "      <td>-0.198505</td>\n",
              "      <td>-0.173754</td>\n",
              "      <td>-0.191887</td>\n",
              "      <td>0.452607</td>\n",
              "      <td>-0.186006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>-0.169098</td>\n",
              "      <td>0.062486</td>\n",
              "      <td>0.575665</td>\n",
              "      <td>0.112573</td>\n",
              "      <td>-0.112125</td>\n",
              "      <td>-0.112125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>-0.075000</td>\n",
              "      <td>-0.075000</td>\n",
              "      <td>-0.099750</td>\n",
              "      <td>-0.075000</td>\n",
              "      <td>0.660464</td>\n",
              "      <td>-0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>0.246002</td>\n",
              "      <td>-0.050000</td>\n",
              "      <td>0.932407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.391115</td>\n",
              "      <td>0.318075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>-0.368034</td>\n",
              "      <td>-0.016971</td>\n",
              "      <td>-0.364964</td>\n",
              "      <td>-0.352746</td>\n",
              "      <td>-0.364410</td>\n",
              "      <td>-0.368810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>-0.279224</td>\n",
              "      <td>-0.113015</td>\n",
              "      <td>-0.197577</td>\n",
              "      <td>-0.245420</td>\n",
              "      <td>-0.253367</td>\n",
              "      <td>-0.117174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>-0.167567</td>\n",
              "      <td>-0.154114</td>\n",
              "      <td>-0.165009</td>\n",
              "      <td>-0.173878</td>\n",
              "      <td>0.150669</td>\n",
              "      <td>-0.198289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>-0.149251</td>\n",
              "      <td>0.116937</td>\n",
              "      <td>-0.149251</td>\n",
              "      <td>-0.149251</td>\n",
              "      <td>-0.149251</td>\n",
              "      <td>-0.143126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>-0.272785</td>\n",
              "      <td>-0.249309</td>\n",
              "      <td>-0.277922</td>\n",
              "      <td>-0.280752</td>\n",
              "      <td>0.136655</td>\n",
              "      <td>-0.243911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>-0.194871</td>\n",
              "      <td>0.200755</td>\n",
              "      <td>-0.174002</td>\n",
              "      <td>-0.162417</td>\n",
              "      <td>-0.213532</td>\n",
              "      <td>-0.198381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>-0.149251</td>\n",
              "      <td>-0.167395</td>\n",
              "      <td>-0.104554</td>\n",
              "      <td>0.249875</td>\n",
              "      <td>-0.155501</td>\n",
              "      <td>-0.149314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>-0.137000</td>\n",
              "      <td>0.763788</td>\n",
              "      <td>-0.149251</td>\n",
              "      <td>-0.124625</td>\n",
              "      <td>-0.115747</td>\n",
              "      <td>0.060934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>-0.199029</td>\n",
              "      <td>-0.161689</td>\n",
              "      <td>-0.168518</td>\n",
              "      <td>-0.185294</td>\n",
              "      <td>0.226592</td>\n",
              "      <td>-0.155848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>-0.136689</td>\n",
              "      <td>-0.159855</td>\n",
              "      <td>-0.149251</td>\n",
              "      <td>-0.125881</td>\n",
              "      <td>0.560207</td>\n",
              "      <td>-0.176890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>-0.099750</td>\n",
              "      <td>-0.075000</td>\n",
              "      <td>-0.099750</td>\n",
              "      <td>-0.099750</td>\n",
              "      <td>0.684330</td>\n",
              "      <td>0.181762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>0.532748</td>\n",
              "      <td>0.847917</td>\n",
              "      <td>-0.066778</td>\n",
              "      <td>-0.105783</td>\n",
              "      <td>0.459800</td>\n",
              "      <td>-0.074750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>-0.173358</td>\n",
              "      <td>-0.198505</td>\n",
              "      <td>-0.198505</td>\n",
              "      <td>-0.198505</td>\n",
              "      <td>0.542304</td>\n",
              "      <td>-0.198505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>-0.131374</td>\n",
              "      <td>-0.120324</td>\n",
              "      <td>-0.149251</td>\n",
              "      <td>-0.112001</td>\n",
              "      <td>0.735688</td>\n",
              "      <td>-0.149251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>0.377890</td>\n",
              "      <td>-0.099750</td>\n",
              "      <td>-0.099750</td>\n",
              "      <td>0.313741</td>\n",
              "      <td>0.981613</td>\n",
              "      <td>-0.074750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         left     right   forward  backward        up      down\n",
              "000 -0.727493 -0.709291 -0.439680 -0.624663 -0.621734 -0.685483\n",
              "001 -0.575510 -0.299116 -0.580253 -0.564337 -0.571451 -0.584132\n",
              "002 -0.409343 -0.383465 -0.383260 -0.406132 -0.282102 -0.451487\n",
              "003 -0.330279 -0.288272 -0.200506 -0.296275 -0.332725 -0.318419\n",
              "010 -0.648876 -0.625435 -0.246483 -0.601730 -0.478675 -0.639680\n",
              "011 -0.494845 -0.137551 -0.503505 -0.500063 -0.489243 -0.527051\n",
              "012 -0.372559 -0.358729 -0.394802 -0.391114 -0.181549 -0.405842\n",
              "013 -0.262582  0.201183 -0.273221 -0.247512 -0.210634 -0.256714\n",
              "020 -0.503763 -0.533528 -0.536116 -0.518705 -0.184594 -0.511744\n",
              "021 -0.476565 -0.406985 -0.429889 -0.446039  0.086096 -0.428947\n",
              "022 -0.287193 -0.294008 -0.257529 -0.271894  0.302627 -0.267942\n",
              "023 -0.207449 -0.230781  0.375436 -0.015739 -0.198596 -0.192132\n",
              "030 -0.447153 -0.488899 -0.510326 -0.488899 -0.365281 -0.455075\n",
              "031 -0.364457 -0.416799 -0.027034 -0.369950 -0.376162 -0.384085\n",
              "032 -0.282318 -0.183548  0.309098 -0.289379 -0.265154 -0.265890\n",
              "033 -0.241479 -0.272016  0.512946 -0.077382 -0.049500 -0.268600\n",
              "100 -0.565791 -0.557605 -0.306946 -0.593690 -0.545794 -0.545941\n",
              "101 -0.440782 -0.510128 -0.138927 -0.431649 -0.414145 -0.431542\n",
              "102 -0.351109 -0.350461 -0.350197 -0.356410 -0.112315 -0.379123\n",
              "103 -0.234954  0.116300 -0.229042 -0.252070 -0.263959 -0.215421\n",
              "110 -0.518060 -0.082275 -0.498799 -0.555309 -0.532275 -0.520876\n",
              "111 -0.369768 -0.076763 -0.412677 -0.407914 -0.326146 -0.406423\n",
              "112 -0.251992 -0.285361 -0.231699 -0.239732  0.026181 -0.244870\n",
              "113 -0.155895  0.176083 -0.173754 -0.167814 -0.174927 -0.160509\n",
              "120 -0.392719 -0.426442  0.033982 -0.330107 -0.428672 -0.420871\n",
              "121 -0.242263 -0.237164 -0.159277 -0.271578  0.261864 -0.240283\n",
              "122 -0.123061 -0.149314 -0.168367 -0.190554  0.107535 -0.207416\n",
              "123 -0.123778  0.361044  0.166270 -0.042239 -0.075000 -0.129641\n",
              "130 -0.317175 -0.343736  0.063371 -0.362607 -0.369596 -0.341701\n",
              "131 -0.198727 -0.186192 -0.192317 -0.186067  0.256258 -0.192226\n",
              "132 -0.161689 -0.149251  0.197351 -0.209039 -0.173816 -0.136751\n",
              "133 -0.112001 -0.112001  0.607120 -0.074750 -0.050000  0.164343\n",
              "200 -0.466588 -0.498225 -0.141782 -0.492023 -0.474595 -0.483339\n",
              "201 -0.332664  0.015541 -0.321412 -0.385102 -0.275829 -0.364409\n",
              "202 -0.198505 -0.219738 -0.017289 -0.198505 -0.215397 -0.223009\n",
              "203 -0.149251  0.350384 -0.167629 -0.136876 -0.161564 -0.198631\n",
              "210 -0.322608  0.071911 -0.331681 -0.332009 -0.370910 -0.312695\n",
              "211 -0.238677  0.086940 -0.276616 -0.214134 -0.214015 -0.295121\n",
              "212 -0.183067  0.419054 -0.135585 -0.149251 -0.136751 -0.175235\n",
              "213 -0.137000  0.557325 -0.102897 -0.112250 -0.124376 -0.099750\n",
              "220 -0.283623  0.212633 -0.125146 -0.195984 -0.281145 -0.277805\n",
              "221 -0.227449 -0.181176  0.256348 -0.134322 -0.195257 -0.182943\n",
              "222 -0.130203 -0.087933 -0.099750 -0.099750  0.555568 -0.105316\n",
              "223 -0.112001  0.637082 -0.074750 -0.074750  0.180955 -0.074750\n",
              "230 -0.186742 -0.198505 -0.173754 -0.191887  0.452607 -0.186006\n",
              "231 -0.169098  0.062486  0.575665  0.112573 -0.112125 -0.112125\n",
              "232 -0.075000 -0.075000 -0.099750 -0.075000  0.660464 -0.050000\n",
              "233  0.246002 -0.050000  0.932407  0.000000  0.391115  0.318075\n",
              "300 -0.368034 -0.016971 -0.364964 -0.352746 -0.364410 -0.368810\n",
              "301 -0.279224 -0.113015 -0.197577 -0.245420 -0.253367 -0.117174\n",
              "302 -0.167567 -0.154114 -0.165009 -0.173878  0.150669 -0.198289\n",
              "303 -0.149251  0.116937 -0.149251 -0.149251 -0.149251 -0.143126\n",
              "310 -0.272785 -0.249309 -0.277922 -0.280752  0.136655 -0.243911\n",
              "311 -0.194871  0.200755 -0.174002 -0.162417 -0.213532 -0.198381\n",
              "312 -0.149251 -0.167395 -0.104554  0.249875 -0.155501 -0.149314\n",
              "313 -0.137000  0.763788 -0.149251 -0.124625 -0.115747  0.060934\n",
              "320 -0.199029 -0.161689 -0.168518 -0.185294  0.226592 -0.155848\n",
              "321 -0.136689 -0.159855 -0.149251 -0.125881  0.560207 -0.176890\n",
              "322 -0.099750 -0.075000 -0.099750 -0.099750  0.684330  0.181762\n",
              "323  0.532748  0.847917 -0.066778 -0.105783  0.459800 -0.074750\n",
              "330 -0.173358 -0.198505 -0.198505 -0.198505  0.542304 -0.198505\n",
              "331 -0.131374 -0.120324 -0.149251 -0.112001  0.735688 -0.149251\n",
              "332  0.377890 -0.099750 -0.099750  0.313741  0.981613 -0.074750\n",
              "333  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa3JV8qmAnIN"
      },
      "source": [
        "# Test populated Q-table\n",
        "Observe the agent's steps using trained Q-table\n",
        "<br> Is similar to `test_cube()`, but `train()` is removed\n",
        "<br> Calculates average steps per episode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7QGjEzLIU44",
        "outputId": "0b80cd5a-6b63-40da-8b39-dfa20e584934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "max_episode = 500\n",
        "steps_sum = 0\n",
        "\n",
        "for epsisode_num in range(0, max_episode):\n",
        "    state = env.reset()\n",
        "    terminate = False\n",
        "    t = 0\n",
        "    episode_reward = 0\n",
        "\n",
        "    while not terminate:        \n",
        "        action = agent.take_action(state) # choose a random action or highest action\n",
        "\n",
        "        reward, terminate, next_state = env.step(action)\n",
        "        episode_reward += reward\n",
        "        t += 1\n",
        "        state = next_state\n",
        "    print(f'epsisode: {epsisode_num}, total_steps: {t} episode reward: {episode_reward}')    \n",
        "    steps_sum += t # compute steps sum\n",
        "\n",
        "# end of loop\n",
        "print(\"Averge steps of agent per episode = \", steps_sum/max_episode)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epsisode: 0, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 1, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 2, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 3, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 4, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 5, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 6, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 7, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 8, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 9, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 10, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 11, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 12, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 13, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 14, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 15, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 16, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 17, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 18, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 19, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 20, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 21, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 22, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 23, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 24, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 25, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 26, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 27, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 28, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 29, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 30, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 31, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 32, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 33, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 34, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 35, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 36, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 37, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 38, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 39, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 40, total_steps: 32 episode reward: -2.1000000000000014\n",
            "epsisode: 41, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 42, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 43, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 44, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 45, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 46, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 47, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 48, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 49, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 50, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 51, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 52, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 53, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 54, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 55, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 56, total_steps: 31 episode reward: -2.0000000000000013\n",
            "epsisode: 57, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 58, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 59, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 60, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 61, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 62, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 63, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 64, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 65, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 66, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 67, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 68, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 69, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 70, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 71, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 72, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 73, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 74, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 75, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 76, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 77, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 78, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 79, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 80, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 81, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 82, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 83, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 84, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 85, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 86, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 87, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 88, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 89, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 90, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 91, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 92, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 93, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 94, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 95, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 96, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 97, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 98, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 99, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 100, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 101, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 102, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 103, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 104, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 105, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 106, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 107, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 108, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 109, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 110, total_steps: 41 episode reward: -3.0000000000000018\n",
            "epsisode: 111, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 112, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 113, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 114, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 115, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 116, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 117, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 118, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 119, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 120, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 121, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 122, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 123, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 124, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 125, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 126, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 127, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 128, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 129, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 130, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 131, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 132, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 133, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 134, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 135, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 136, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 137, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 138, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 139, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 140, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 141, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 142, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 143, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 144, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 145, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 146, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 147, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 148, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 149, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 150, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 151, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 152, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 153, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 154, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 155, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 156, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 157, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 158, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 159, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 160, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 161, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 162, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 163, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 164, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 165, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 166, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 167, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 168, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 169, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 170, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 171, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 172, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 173, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 174, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 175, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 176, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 177, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 178, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 179, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 180, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 181, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 182, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 183, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 184, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 185, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 186, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 187, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 188, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 189, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 190, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 191, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 192, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 193, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 194, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 195, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 196, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 197, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 198, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 199, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 200, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 201, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 202, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 203, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 204, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 205, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 206, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 207, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 208, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 209, total_steps: 31 episode reward: -2.0000000000000013\n",
            "epsisode: 210, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 211, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 212, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 213, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 214, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 215, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 216, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 217, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 218, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 219, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 220, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 221, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 222, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 223, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 224, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 225, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 226, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 227, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 228, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 229, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 230, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 231, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 232, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 233, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 234, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 235, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 236, total_steps: 34 episode reward: -2.3000000000000016\n",
            "epsisode: 237, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 238, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 239, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 240, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 241, total_steps: 28 episode reward: -1.700000000000001\n",
            "epsisode: 242, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 243, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 244, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 245, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 246, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 247, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 248, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 249, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 250, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 251, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 252, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 253, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 254, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 255, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 256, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 257, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 258, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 259, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 260, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 261, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 262, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 263, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 264, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 265, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 266, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 267, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 268, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 269, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 270, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 271, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 272, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 273, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 274, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 275, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 276, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 277, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 278, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 279, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 280, total_steps: 25 episode reward: -1.4000000000000008\n",
            "epsisode: 281, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 282, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 283, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 284, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 285, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 286, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 287, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 288, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 289, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 290, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 291, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 292, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 293, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 294, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 295, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 296, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 297, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 298, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 299, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 300, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 301, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 302, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 303, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 304, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 305, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 306, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 307, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 308, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 309, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 310, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 311, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 312, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 313, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 314, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 315, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 316, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 317, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 318, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 319, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 320, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 321, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 322, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 323, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 324, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 325, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 326, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 327, total_steps: 26 episode reward: -1.5000000000000009\n",
            "epsisode: 328, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 329, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 330, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 331, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 332, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 333, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 334, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 335, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 336, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 337, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 338, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 339, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 340, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 341, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 342, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 343, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 344, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 345, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 346, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 347, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 348, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 349, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 350, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 351, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 352, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 353, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 354, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 355, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 356, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 357, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 358, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 359, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 360, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 361, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 362, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 363, total_steps: 27 episode reward: -1.600000000000001\n",
            "epsisode: 364, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 365, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 366, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 367, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 368, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 369, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 370, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 371, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 372, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 373, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 374, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 375, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 376, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 377, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 378, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 379, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 380, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 381, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 382, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 383, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 384, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 385, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 386, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 387, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 388, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 389, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 390, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 391, total_steps: 29 episode reward: -1.8000000000000012\n",
            "epsisode: 392, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 393, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 394, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 395, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 396, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 397, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 398, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 399, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 400, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 401, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 402, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 403, total_steps: 30 episode reward: -1.9000000000000012\n",
            "epsisode: 404, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 405, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 406, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 407, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 408, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 409, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 410, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 411, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 412, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 413, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 414, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 415, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 416, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 417, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 418, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 419, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 420, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 421, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 422, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 423, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 424, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 425, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 426, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 427, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 428, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 429, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 430, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 431, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 432, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 433, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 434, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 435, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 436, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 437, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 438, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 439, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 440, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 441, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 442, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 443, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 444, total_steps: 9 episode reward: 0.20000000000000007\n",
            "epsisode: 445, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 446, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 447, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 448, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 449, total_steps: 20 episode reward: -0.9000000000000006\n",
            "epsisode: 450, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 451, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 452, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 453, total_steps: 23 episode reward: -1.2000000000000006\n",
            "epsisode: 454, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 455, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 456, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 457, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 458, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 459, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 460, total_steps: 22 episode reward: -1.1000000000000005\n",
            "epsisode: 461, total_steps: 21 episode reward: -1.0000000000000004\n",
            "epsisode: 462, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 463, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 464, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 465, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 466, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 467, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 468, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 469, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 470, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 471, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 472, total_steps: 19 episode reward: -0.8000000000000005\n",
            "epsisode: 473, total_steps: 17 episode reward: -0.6000000000000003\n",
            "epsisode: 474, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 475, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 476, total_steps: 11 episode reward: 1.1102230246251565e-16\n",
            "epsisode: 477, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 478, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 479, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 480, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 481, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 482, total_steps: 24 episode reward: -1.3000000000000007\n",
            "epsisode: 483, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 484, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 485, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 486, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 487, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 488, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 489, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 490, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 491, total_steps: 12 episode reward: -0.09999999999999987\n",
            "epsisode: 492, total_steps: 16 episode reward: -0.5000000000000002\n",
            "epsisode: 493, total_steps: 14 episode reward: -0.30000000000000004\n",
            "epsisode: 494, total_steps: 10 episode reward: 0.10000000000000009\n",
            "epsisode: 495, total_steps: 15 episode reward: -0.40000000000000013\n",
            "epsisode: 496, total_steps: 13 episode reward: -0.19999999999999996\n",
            "epsisode: 497, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 498, total_steps: 18 episode reward: -0.7000000000000004\n",
            "epsisode: 499, total_steps: 28 episode reward: -1.700000000000001\n",
            "Averge steps of agent per episode =  15.536\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}